{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d280cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fitz  # PyMuPDF\n",
    "# import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f70d49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to extract text from a specific rectangular area of a page\n",
    "# def extract_text_from_rect(page, rect):\n",
    "#     # Extract text directly from the rectangle area of the page\n",
    "#     clip = page.get_text(\"blocks\", clip=rect)\n",
    "#     text = \"\"\n",
    "#     for block in clip:\n",
    "#         text += block[4] + \"\\n\"\n",
    "#     return text\n",
    "\n",
    "# # Function to split a page vertically and extract text from both parts\n",
    "# def split_and_extract_text(page, remove_bottom=0):\n",
    "#     rect = page.rect\n",
    "#     mid_x = rect.width / 2\n",
    "#     page_height = rect.height\n",
    "\n",
    "#     # Adjust bottom of the rectangle to remove a specified portion\n",
    "#     top_y = rect.tl.y\n",
    "#     bottom_y = rect.br.y - remove_bottom\n",
    "#     adjusted_rect = fitz.Rect(rect.tl, fitz.Point(rect.br.x, bottom_y))\n",
    "\n",
    "#     # Define left and right rectangles\n",
    "#     left_rect = fitz.Rect(rect.tl, fitz.Point(mid_x, bottom_y))\n",
    "#     right_rect = fitz.Rect(fitz.Point(mid_x, top_y), fitz.Point(rect.br.x, bottom_y))\n",
    "\n",
    "#     # Extract text from left part\n",
    "#     left_text = extract_text_from_rect(page, left_rect)\n",
    "\n",
    "#     # Extract text from right part\n",
    "#     right_text = extract_text_from_rect(page, right_rect)\n",
    "\n",
    "#     return left_text, right_text\n",
    "\n",
    "# # Path to the original PDF\n",
    "# pdf_path = \"ICAM_2023.pdf\"\n",
    "\n",
    "# # Open the PDF\n",
    "# doc = fitz.open(pdf_path)\n",
    "\n",
    "# # Extract and arrange text\n",
    "# arranged_text = \"\"\n",
    "\n",
    "# for page_num in range(len(doc)):\n",
    "#     page = doc.load_page(page_num)\n",
    "    \n",
    "#     # Remove 100 pixels (adjust this value as needed) from the bottom before splitting\n",
    "#     left_text, right_text = split_and_extract_text(page, remove_bottom=50)\n",
    "    \n",
    "#     arranged_text += left_text + \"\\n\" + right_text + \"\\n\"\n",
    "\n",
    "# # Print the arranged text\n",
    "# print(arranged_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3127dcd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18607f19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ac3058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae743e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fae6e00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "988eea24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import streamlit as st\n",
    "from PyPDF2 import PdfReader\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.prompts import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d18593f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import streamlit as st\n",
    "import google.generativeai as genai\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from PyPDF2 import PdfReader\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18b4b236",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-12 15:58:20.504 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\alonakadi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-09-12 15:58:20.504 Session state does not function when running a script without `streamlit run`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "load_dotenv()\n",
    "os.getenv(\"GOOGLE_API_KEY\")\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "\n",
    "# Extract all of the texts from the PDF files \n",
    "def get_pdf_text(pdfs):\n",
    "  text = \"\"\n",
    "  for pdf in pdfs:\n",
    "    pdf_reader = PdfReader(pdf)\n",
    "\n",
    "    # iterate through all the pages in the pdf\n",
    "    for page in pdf_reader.pages:\n",
    "      text += page.extract_text()\n",
    "    \n",
    "    return text \n",
    "\n",
    "# Split text into chunks \n",
    "def generate_chunks(text):\n",
    "  text_splitter = RecursiveCharacterTextSplitter(\n",
    "      chunk_size=1000,\n",
    "      chunk_overlap=1000\n",
    "  )\n",
    "\n",
    "  chunks = text_splitter.split_text(text)\n",
    "\n",
    "  return chunks \n",
    "\n",
    "# Convert Chunks into Vectors\n",
    "def chunks_to_vectors(chunks):\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "    try:\n",
    "        vector_store = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
    "        vector_store.save_local(\"faiss_index\")  # Save the updated index\n",
    "    except Exception as e:\n",
    "        print(\"Error in loading FAISS index:\", e)\n",
    "        raise\n",
    "  # vector_store = FAISS.from_texts(chunks, embeddings)\n",
    "   #vector_store.save_local(\"faiss_index\")\n",
    "\n",
    "\n",
    "def get_conversation():\n",
    "    prompt_template = \"\"\"\n",
    "    Answer the question that is asked with as much detail as you can, given the context that has been provided. If you unable to come up with an answer based on the provided context,\n",
    "    simply say \"Answer cannot be provided based on the context that has been provided\", instead of trying to forcibly provide an answer.\\n\\n\n",
    "    Context: \\n {context}?\\n\n",
    "    Question: \\n {question}\\n\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    model = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.3)\n",
    "\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "    chain = load_qa_chain(model, chain_type=\"stuff\", prompt=prompt)\n",
    "    return chain \n",
    "\n",
    "def user_input(question):\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "    new_db = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
    "    docs = new_db.similarity_search(question)\n",
    "\n",
    "    chain = get_conversation()\n",
    "\n",
    "    response = chain(\n",
    "        {\"input_documents\": docs, \"question\": question}, return_only_outputs=True\n",
    "    )\n",
    "\n",
    "    st.write(\"Reply: \", response[\"output_text\"])\n",
    "\n",
    "\n",
    "# Main app portion of the project\n",
    "# Main app portion of the project\n",
    "def app():\n",
    "    st.title(\"ASTM Documents Analyzer\")\n",
    "    st.sidebar.title(\"Upload Documents\")\n",
    "\n",
    "    # Sidebar\n",
    "    pdf_docs = st.sidebar.file_uploader(\"Upload your documents in PDF format, then click Analyze.\", accept_multiple_files=True)\n",
    "\n",
    "    analyze_triggered = st.sidebar.button(\"Analyze\")\n",
    "\n",
    "    if analyze_triggered:\n",
    "        with st.spinner(\"Analyzing... ‚è≥\"):\n",
    "            raw_text = get_pdf_text(pdf_docs)\n",
    "            chunks = generate_chunks(raw_text)\n",
    "            chunks_to_vectors(chunks)\n",
    "            st.success(\"Done\")\n",
    "\n",
    "    # User Input \n",
    "    user_question = st.text_input(\"Ask a question based on the documents that were uploaded\")\n",
    "\n",
    "    if user_question:\n",
    "        user_input(user_question)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72457c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b287a7ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbcd6a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
